<!DOCTYPE html>
<html>
<title>Improved Techniques for Training GANs - A Reproduction Study</title>

<body>
    <h1>Improved Techniques for Training GANs - A Reproduction Study</h1>
    <h2>Arka Daw - Mohannad Elhamod - Snehal More</h2>
    <br />
    <h1>Introduction</h1>
    <p>In this report, we attempt to reproduce the results found in the <a
            href="https://arxiv.org/abs/1606.03498">Improved Techniques for Training GANs</a> paper. This paper proposes
        several improvements to the <a href="https://arxiv.org/abs/1406.2661">original GANs paper</a>, namely: feature
        matching, minibatch discrimination, historical averaging, one-side label smoothing, and virtual batch
        normalization. The paper also proposed a semi-supervised learning method, leveraging fake unlabeled data samples
        to improve results.</p>
    <p>While the authors demonstrate their work by showing result from several wholistic and ablation experiments. Here,
        we choose to reproduce only some of those results from two datasets: CIFAR and MNIST.</p>
    <h1>CIFAR</h1>
    <p>Arka and Snehal will talk about this.</p>
    | Command | Description |
| --- | --- |
| git status | List all new or modified files |
| git diff | Show file differences that haven't been staged |
    <h1>MNIST</h1>
    <p>MNIST is a large image dataset of single digits. In this report, we adopt the code created by <a
            href="https://github.com/Sleepychord/ImprovedGAN-pytorch">Sleepychord</a>. Some effort was spent to rerun
        the code by commiting minor code changes and updating outdated packages. The table below compares our results to
        those mentioned in the paper:</p>
    <table style="width:100%">
        <tr>
            <th>Experiment (Number of labeled examples)</th>
            <th>The paper's results (Number of incorrectly predicted test examples out of 10000)</th>
            <th>Our results (Number of incorrectly predicted test examples out of 10000)</th>
        </tr>
        <tr>
            <td>20</td>
            <td>1677 ± 452</td>
            <td>1952 ± 226.7</td>
        </tr>
        <tr>
            <td>50</td>
            <td>221 ± 136</td>
            <td>569 ± 11.1</td>
        </tr>
        <tr>
            <td>100</td>
            <td>93 ± 6.5</td>
            <td>433 ± 7.9</td>
        </tr>
        <tr>
            <td>200</td>
            <td>90 ± 4.2</td>
            <td>398 ± 13.9</td>
        </tr>
    </table>
    <p>It can be noticed that our results follow the same trend observed in the paoer, namely that the higher the number
        of labelled training samples is, the lower the number of incorrectly predicted test examples is. However, our
        results have a somehwat higher error rate. While the paper does not mention any details about the tests set, we
        assumed they use the entire MNIST test set as provided. Also, we ran our model 3 times for each experiment and
        recorded the mean and standard deviation for the purposes of comparison.</p>
    <p>The following also shows generated fake data from each experiment and compares to that shown in the paper:</p>
    <table style="width:100%">
        <tr>
            <th>Experiment (Number of labeled examples)</th>
            <th colspan="3">Fake data</th>
        </tr>
        <tr>
            <td>20</td>
            <td><img src=".\20_1.png"></td>
            <td><img src=".\20_2.png"></td>
            <td><img src=".\20_3.png"></td>
        </tr>
        <tr>
            <td>50</td>
            <td><img src=".\50_1.png"></td>
            <td><img src=".\50_2.png"></td>
            <td><img src=".\50_3.png"></td>
        </tr>
        <tr>
            <td>100</td>
            <td><img src=".\100_1.png"></td>
            <td><img src=".\100_2.png"></td>
            <td><img src=".\100_3.png"></td>
        </tr>   
        <tr>
            <td>200</td>
            <td><img src=".\200_1.png"></td>
            <td><img src=".\200_2.png"></td>
            <td><img src=".\200_3.png"></td>
        </tr>
        <tr>
            <td>The paper's</td>
            <td><img src=".\real.PNG"></td>
            <td></td>
            <td></td>
        </tr>
    </table>
    <p>The fake images we obtained are similar in nature to those reported in the paper. However, we suspect that the
        authors applied some image processing, such as smoothing, to their results as the raw output of the code we ran
        seems to produce some visual noise.</p>

</body>

</html>
